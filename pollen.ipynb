{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import requests_cache\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "requests_cache.install_cache('pollen', backend='sqlite')\n",
    "%matplotlib inline\n",
    "\n",
    "# %mkdir cache\n",
    "import joblib; mem = joblib.Memory(cachedir='cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import util.pollen_utils; reload(util.pollen_utils); from util.pollen_utils import (\n",
    "    pollen_url, pollen_date2df as pollen_date2df_, pollen_data as pollen_data_\n",
    ")\n",
    "\n",
    "import util.utils; reload(util.utils); from util.utils import (\n",
    "    check_one2one, yrmths, flatten_multindex, ends_with,\n",
    "    batchify, test_batchify, collapse_dims, test_collapse_dims_,\n",
    "    batch_getterer,\n",
    "    to_sub_seqs, test_to_sub_seqs,\n",
    "    ravel, repackage_hidden, mse\n",
    ")\n",
    "date = lambda xs: dt.datetime(*xs)\n",
    "\n",
    "test_to_sub_seqs()\n",
    "test_batchify()\n",
    "pollen_date2df = mem.cache(pollen_date2df_)\n",
    "pollen_data = mem.cache(pollen_data_)\n",
    "test_collapse_dims_(T)\n",
    ";;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# u = pollen_url.format(year=2014, month=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    for yr in range(2000, 2018):\n",
    "        for m in range(1, 13):\n",
    "            u = url.format(year=yr, month=m)\n",
    "            r = requests.get(u)\n",
    "            print(yr, m, end='; ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process monthly calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "body > div:nth-child(7) > div > div > div > div > div:nth-child(3) > div.calendar-wrapper > div > div.calendar-body.rows-5 > div.calendar-row.calendar-row-4 > div:nth-child(2) > div > span.count > a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "r = requests.get(u)\n",
    "soup = BeautifulSoup(r.content, \"lxml\")\n",
    "sel = 'div.calendar-row.calendar-row-4 > div > div > span.count > a'\n",
    "soup.select_one(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sometimes Jan calendar will have counts from days\n",
    "# at beginning of Feb or end or previous Dec.\n",
    "# Just checking that they agree w/ numbers in\n",
    "# those months' calendars before dropping dupe\n",
    "# dates\n",
    "poldf = pollen_data(yrmths)\n",
    "check_one2one(poldf, 'Date', 'Count')\n",
    "\n",
    "poldf = poldf.drop_duplicates('Date').reset_index(drop=1)\n",
    "poldf.loc[poldf.Count == -1, 'Count'] = np.nan\n",
    "poldf = poldf.dropna(axis=0)\n",
    "poldf.Date = pd.to_datetime(poldf.Date)\n",
    "\n",
    "poldf = poldf.assign(\n",
    "    Yr =lambda x: x.Date.dt.year,\n",
    "    M  =lambda x: x.Date.dt.month,\n",
    "    D  =lambda x: x.Date.dt.day,\n",
    "    Doy=lambda x: x.Date.dt.dayofyear,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "- Historic average residuals\n",
    "- Compare embeddings for wthr w/ summaries\n",
    "- standardize time fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "pdf.plot(y='Count', x='Date', ax=plt.gca())\n",
    "\n",
    "d = pdf[:].reset_index(drop=0).set_index(['Doy', 'Yr']).Count.unstack()\n",
    "d\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "d.iloc[:150, 8:].plot(ax=plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get historical weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    # Src 1\n",
    "    import util.wthr_utils; reload(util.wthr_utils); from util.wthr_utils import (\n",
    "        wtr_date2df as wtr_date2df_, wthr_data as wthr_data_,\n",
    "        wthr, add_dates\n",
    "    )\n",
    "\n",
    "    wtr_date2df = mem.cache(wtr_date2df_)\n",
    "    wthr_data = mem.cache(wthr_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Src 2\n",
    "dailydf = feather.read_dataframe('cache/dark_day.fth')\n",
    "hr_df = feather.read_dataframe('cache/dark_hr.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dailydf['Dt'] = pd.to_datetime(dailydf.Time, unit='s')\n",
    "dailydf['Day'] = dailydf.Dt.dt.day\n",
    "dailydf['M'] = dailydf.Dt.dt.month\n",
    "dailydf['Y'] = dailydf.Dt.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rep_with_dummies_(df, col):\n",
    "    df = df.copy()\n",
    "    newcs = pd.get_dummies(df[col]).astype(int)\n",
    "    for c in newcs:\n",
    "        df[c] = newcs[c]\n",
    "    return df.drop(col, axis=1)\n",
    "\n",
    "def rep_with_dummies(df, cols):\n",
    "    \"\"\"Return a copy of df w/ each of `cols` replaced\n",
    "    with its dummified self\"\"\"\n",
    "    for c in cols:\n",
    "        df = rep_with_dummies_(df, c)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Float/nulls\n",
    "\n",
    "#### Precip_type, Precip_accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailydf.loc[dailydf.eval('Precip_type != Precip_type'), 'Precip_type'] = 'none'\n",
    "dailydf['Precip_accumulation'] = dailydf.Precip_accumulation.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailydf['Min_time'] = dailydf.Dt.map(lambda t: int(t.replace(hour=0).strftime('%s')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_pimt_null(s, timecol):\n",
    "    \"\"\"This column is null when there is no precipitation.\n",
    "    Not sure of anything better to do, so I'm just setting\n",
    "    it to the minimum time of the day in question\n",
    "    \"\"\"\n",
    "    s2 = s.copy()\n",
    "    null_ptime = s.isnull()\n",
    "    s2.loc[null_ptime] = timecol[null_ptime]\n",
    "    return s2.astype(int)\n",
    "\n",
    "dailydf.Precip_intensity_max_time = fill_pimt_null(dailydf.Precip_intensity_max_time, dailydf.Min_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud_cover\n",
    "- Only if snow\n",
    "Visibility\n",
    "Y Precip_intensity Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf = rep_with_dummies(dailydf, 'Icon Precip_type'.split())  # Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def fill_cloud_cover_null(cc, X):\n",
    "    \"\"\"Solution wasn't obvious, so I just imputed the nulls\n",
    "    with a random forest using the other columns.\n",
    "    \"\"\"\n",
    "    null = cc != cc\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=30, oob_score=True)\n",
    "    rf.fit(X[~null], cc[~null])\n",
    "    cc2 = cc.copy()\n",
    "    cc2.loc[null] = rf.predict(X[null])\n",
    "    \n",
    "    return cc2\n",
    "\n",
    "_feats = [k for k, v in ddf.dtypes.items() if (v == int) or (v == float) and k != 'Cloud_cover']\n",
    "ddf['Cloud_cover'] = fill_cloud_cover_null(ddf.Cloud_cover, ddf[_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert (ddf == ddf).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that within a day the difference between maximum\n",
    "# and minimum times are not greater than the\n",
    "# number of seconds in a day\n",
    "\n",
    "times = lfilter(lambda x: x.endswith('ime'), dailydf)\n",
    "minmax = DataFrame({\n",
    "    'Min': dailydf[times].min(axis=1),\n",
    "    'Max': dailydf[times].max(axis=1),\n",
    "}).assign(Diff=lambda x: x.Max.sub(x.Min).div(60 * 60 * 24)) \n",
    "\n",
    "assert 0 <= minmax.Diff.max() <= 1\n",
    "minmax.Diff.max()  # should be no more than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert (dailydf[times].min(axis=1) == dailydf.Min_time).all(), 'Min_time definition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unix_time_to_day_hrs = lambda s, min_time: (s - min_time) / 3600\n",
    "\n",
    "for t in set(times) - {'Min_time'}:\n",
    "    c = t + 's'\n",
    "    dailydf[c] = unix_time_to_day_hrs(dailydf[t], dailydf.Min_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('cloud_cover_model_perf.png', height=400, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hr_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with requests_cache.disabled():\n",
    "#     r = requests.get(u)\n",
    "    wtr_date2df(2017, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wdf = wthr_data(yrmths)\n",
    "wdf = wthr_data_(yrmths[:], wtr_date2df=wtr_date2df)\n",
    "\n",
    "# Weird dupe row\n",
    "wdf['Dt'] = lmap(lambda x: dt.datetime(*x), zip(wdf.Yr, wdf.M, wdf.Day))\n",
    "_, bad_ix = wdf[wdf['Dt'] == \"2001-03-31\"].index\n",
    "wdf = wdf[~(wdf.index == bad_ix)].copy().reset_index(drop=1)\n",
    "assert wdf.Dt.value_counts(normalize=0).max() == 1\n",
    "\n",
    "wdf['Doy'] = wdf.Dt.dt.dayofyear\n",
    "# wdf = wdf.set_index('Dt')\n",
    "\n",
    "# Fix 'T'\n",
    "# Prec: '-': only in 2000; 'T': increases later.\n",
    "bm = wdf['Prec'].isin(['T', '-'])\n",
    "wdf.loc[bm, 'Prec'] = np.nan\n",
    "wdf['Prec'] = wdf.Prec.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for Randomness in 'T'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    wdf2 = wdf.assign(Tt=lambda x: ~x.Prec.isin(['T']), Dow=lambda x: x.Dt.dt.dayofweek)\n",
    "    wdf2.columns = flatten_multindex(wdf2)\n",
    "\n",
    "    _dcs = 'Temp_hi Temp_lo Dew_hi Dew_lo Humidity_hi Humidity_lo Press_hi Press_lo Vis_hi Vis_lo'.split()\n",
    "\n",
    "    vdf = wdf2.drop(['Day', 'Dt', 'Event'] + _dcs, axis=1).dropna(axis=0)\n",
    "    _cs = list(vdf)\n",
    "    vdf = vdf[_cs[-1:] + _cs[:-1]]\n",
    "    vdf = vdf.iloc[:, :8]\n",
    "\n",
    "    Tix = vdf.query('~Tt').index.tolist()\n",
    "    Tnix = nr.choice(vdf.query('Tt').index, len(Tix)).tolist()\n",
    "\n",
    "    sns.pairplot(data=vdf.ix[Tix + Tnix], hue=\"Tt\",  markers=\"+\",\n",
    "                      plot_kws=dict(s=50, edgecolor=\"b\", linewidth=1, alpha=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz Wtr & Pollen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_(s):\n",
    "    l = np.log10(s)\n",
    "    bm = np.isnan(s) | np.isinf(s)\n",
    "    l[np.isneginf(l)] = 0\n",
    "#     l[np.isinf(l)] = l.max()\n",
    "#     l[np.isnan(l)] = l.median()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xdf = wdf.assign(\n",
    "    Cnt=lambda x: poldf.set_index('Date').Count.ix[x.Dt].tolist()\n",
    ").assign(\n",
    "    Logcnt=lambda x: log_(x.Cnt)\n",
    ")\n",
    "xdf.columns = flatten_multindex(xdf).assign(Prev_cnt=lambda x: x.Logcnt.shift())\n",
    "# xdf = xdf.query('Doy <= 150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = xdf.Logcnt[:5]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xdf.Event.value_counts(normalize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xdf[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To #Pytorch](#Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_cor = xdf.drop(['Dt', 'Cnt', 'Event', 'Vis_hi', 'Prec'], axis=1).dropna(axis=0).iloc[:, :].corr()\n",
    "sns.clustermap(_cor, standard_scale=1, annot=True, fmt='.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "xdf.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "gdf.Temp_lo.plot()\n",
    "gdf.Logcnt.div(gdf.Logcnt.max()).mul(90).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "la = LassoCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyflux as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "his = ends_with('_hi')(xdf)\n",
    "los = ends_with('_lo')(xdf)\n",
    "xd = xdf.drop(his + los, axis=1).set_index('Dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xd[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xdf[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = pf.ARIMAX(data=xd.query('Yr == 2013'), formula='Logcnt ~ 1+ Temp_avg + Dew_avg + Press_avg', ar=1, ma=1, family=pf.Normal())\n",
    "m = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.plot_fit(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.plot_predict(h=150, past_values=100, oos_data=xd.query('Yr == 2014'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.plot_predict(h=150, past_values=100, oos_data=xd.query('Yr == 2014'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xd.query('Yr == 2014').Logcnt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = model.predict(h=150, oos_data=xd.query('Yr == 2014'), intervals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res0 = model.predict(h=150, oos_data=xd.query('Yr == 2014'), intervals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!say done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xd.groupby(['Yr', \"M\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pp(x, y=None, color=None):\n",
    "    global x_, y_\n",
    "    x_ = x\n",
    "    y_ = y\n",
    "    p = plt.plot(y)\n",
    "    p = plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(xd.set_index('Doy').query('Yr >= 2010 & Yr < 2017'), row='Yr', aspect=4)\n",
    "# g.map(plt.plot, 'Logcnt')\n",
    "g.map(pp, 'Logcnt', 'Prec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-Keras\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Activation, Dropout\n",
    "    from keras.layers.recurrent import LSTM\n",
    "\n",
    "    xd['Nulls'] = xd.isnull().sum(axis=1)\n",
    "    X = xd.drop(['Event', 'Cnt',  'Logcnt'], axis=1).query('Nulls == 0')\n",
    "\n",
    "    xd[:2]\n",
    "\n",
    "    x13 = X.query('Yr == 2013').drop('Yr', axis=1)\n",
    "    y13 = xd.query('Yr == 2013 & Nulls == 0')[['Logcnt']]\n",
    "\n",
    "    _, P = x13.shape\n",
    "\n",
    "    x14 = X.query('Yr == 2014').drop('Yr', axis=1)\n",
    "    y14 = xd.query('Yr == 2014 & Nulls == 0')[['Logcnt']]\n",
    "\n",
    "    x13.shape, y13.shape, P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import toolz.curried as z\n",
    "\n",
    "import torch as T\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pandas.compat import lrange\n",
    "\n",
    "tofloat = lambda x: x.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ycol = 'Logcnt'\n",
    "feats = 'Temp_avg Dew_avg Humidity_avg Wind_avg Prec M Doy'.split()\n",
    "rx_ = xdf[feats + [ycol]].copy()\n",
    "\n",
    "# Null handling\n",
    "rx_['Prec'] = rx_['Prec'].fillna(0)\n",
    "rx_ = rx_.dropna(axis=0)\n",
    "ry = rx_.pop(ycol).astype(dtype=np.float32)\n",
    "\n",
    "# sss = defaultdict(lambda: StandardScaler())\n",
    "ss = StandardScaler()\n",
    "rx = ss.fit_transform(rx_).astype(dtype=np.float32)\n",
    "\n",
    "rx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nr.seed(0)\n",
    "P = 3\n",
    "N = 1000\n",
    "    # x_, y_ = gen_dat2(P=P, N=N, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "nhidden = 21\n",
    "num_layers = 1\n",
    "seq_len = 50\n",
    "bcz = 10\n",
    "\n",
    "to_sub = lambda x: T.from_numpy(to_sub_seqs(x, seq_len=seq_len))\n",
    "xt = to_sub(rx)\n",
    "yt = to_sub(ry)\n",
    "\n",
    "batch_getter, brange = batch_getterer(xt, y=yt, batch_size=bcz, var=True)\n",
    "print('brange', brange)\n",
    "h0 = Variable(T.randn(num_layers, bcz, nhidden))\n",
    "\n",
    "\n",
    "# Write relevant y elements\n",
    "L = np.sum([np.prod(batch_getter(b)[1].size()[:2]) for b in brange])\n",
    "_yeval = yt.numpy().ravel()[:L]\n",
    "feather.write_dataframe(DataFrame(_yeval), '/tmp/res/y.fth')\n",
    "\n",
    "xt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nhidden = 21\n",
    "num_layers = 1\n",
    "seq_len = 50\n",
    "bcz = 10\n",
    "\n",
    "xt = T.from_numpy(rx)\n",
    "yt = T.from_numpy(ry.values[:, None])\n",
    "\n",
    "print(yt.size())\n",
    "print(xt.size())\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(source, i, bptt=20, evaluation=False):\n",
    "    seq_len = min(bptt, len(source) - i)\n",
    "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
    "    return data\n",
    "\n",
    "def seq_batch_iter(x, y=None, bptt=20, evaluation=False):\n",
    "    \"\"\"Iterates according to schema in\n",
    "    http://stackoverflow.com/a/37009670/386279\n",
    "    Every transition seen.\n",
    "    \"\"\"\n",
    "    for i in range(len(x) - 1):\n",
    "        xb = get_batch(x, i, bptt=bptt, evaluation=evaluation)\n",
    "        if y is None:\n",
    "            yield xb\n",
    "        else:\n",
    "            yield xb, get_batch(y, i, bptt=bptt, evaluation=evaluation)\n",
    "            \n",
    "def batch_iter(x, y=None, bptt=20, evaluation=False):\n",
    "    for i in range(0, len(x) - 1, bptt):\n",
    "        xb = get_batch(x, i, bptt=bptt, evaluation=evaluation)\n",
    "        if y is None:\n",
    "            yield xb\n",
    "        else:\n",
    "            yield xb, get_batch(y, i, bptt=bptt, evaluation=evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Rnn(nn.Module):\n",
    "    def __init__(self, P=3, nhidden=21, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.P, self.nhidden, self.num_layers = (\n",
    "            P, nhidden, num_layers\n",
    "        )\n",
    "        self.rnn = nn.GRU(P, nhidden, num_layers, batch_first=True)\n",
    "        # self.rnn.zero_grad()\n",
    "        \n",
    "        self.decoder = nn.Linear(nhidden, 1)\n",
    "        self.init_weights()\n",
    "        self.zero_grad()\n",
    "\n",
    "    def __dir__(self):\n",
    "        return super().__dir__() + list(self._modules)\n",
    "    \n",
    "    def forward(self, input, hidden=None, outputh=False, update_hidden=True):\n",
    "        if hidden is None:\n",
    "            hidden = self.hidden\n",
    "        out1, hout = self.rnn(input, hidden)\n",
    "        out2 = self.decoder(ravel(out1))\n",
    "        self.hidden = repackage_hidden(hout)\n",
    "        if outputh:\n",
    "            return out2, hout\n",
    "        return out2\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        \"For lstm I'll need to return 2\"\n",
    "        weight = next(self.rnn.parameters()).data\n",
    "        mkvar = lambda: Variable(weight.new(self.num_layers, bsz, self.nhidden).zero_())\n",
    "        return mkvar()\n",
    "    \n",
    "    def set_hidden(self, bsz):\n",
    "        h = self.init_hidden(bsz)\n",
    "        self.hidden = h\n",
    "    \n",
    "\n",
    "m = model = Rnn(P=rx.shape[-1], nhidden=nhidden, num_layers=num_layers)\n",
    "model.set_hidden(bcz)\n",
    "# m = model = Rnn()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 0.005)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr = 0.005)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BatchArraySingle(object):\n",
    "    def __init__(self, x=None, seq_len=5, truncate=True, tovar=True):\n",
    "        self.truncate = truncate\n",
    "        self.x = x\n",
    "        self.N = len(x)\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        if truncate:\n",
    "            self.rem = BatchArraySingle(x=x, seq_len=seq_len, truncate=False)\n",
    "            n_segs = self.N // seq_len\n",
    "            # print(n_segs)\n",
    "            self.ix = np.arange(0, n_segs * seq_len, seq_len, dtype=int)\n",
    "            retfuncs = [Variable, T.stack] if tovar else [T.stack]\n",
    "        else:\n",
    "            # remainder\n",
    "            self.ix = np.arange(0, self.N, seq_len, dtype=int)\n",
    "            retfuncs = [list, z.map(Variable)] if tovar else []\n",
    "\n",
    "        self.retfunc = z.compose(*retfuncs)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        bixs = self.ix[ix]\n",
    "        if isint(bixs):\n",
    "            batches = self.x[bixs:bixs+self.seq_len]\n",
    "        else:\n",
    "            batches = [self.x[bix:bix+self.seq_len] for bix in bixs]\n",
    "        return self.retfunc(batches)\n",
    "\n",
    "    idxmax = property(lambda x: len(x.ix) - 1)\n",
    "    \n",
    "    \n",
    "class BatchArray(BatchArraySingle):\n",
    "    def __init__(self, x=None, y=None, seq_len=5, truncate=True, tovar=True, batch_size=20):\n",
    "        super().__init__(x=x, seq_len=seq_len, truncate=truncate, tovar=tovar)\n",
    "        \n",
    "        self.xb = BatchArraySingle(x=x, seq_len=seq_len, truncate=truncate, tovar=tovar)\n",
    "        if truncate:\n",
    "            self.rem = BatchArray(x=x, y=y, seq_len=seq_len, truncate=False, tovar=tovar)\n",
    "        \n",
    "        self.y = y\n",
    "        self.yb = BatchArraySingle(x=y, seq_len=seq_len, truncate=truncate, tovar=tovar)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.xb.__getitem__(ix), self.yb.__getitem__(ix)\n",
    "    \n",
    "    def batch_ix_iter(self, batch_size=None):\n",
    "        batch_size = batch_size or self.batch_size\n",
    "        nb = len(self.ix) // batch_size\n",
    "        return np.arange(nb * batch_size).reshape(-1, batch_size)\n",
    "\n",
    "isint = lambda x: np.issubdtype(type(x), int)\n",
    "\n",
    "# ba = BatchArray(x=x[:], y=y[:], seq_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(barray, model=None, hidden=None, optimizer=None, eval=False, batch_size=None):\n",
    "    batch_size = batch_size or barray.batch_size\n",
    "    assert batch_size or hidden\n",
    "    if hidden is None:\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "    tot_loss = 0\n",
    "    res = []\n",
    "    global x, y, all_elemsb\n",
    "#     all_elemsb = set()\n",
    "\n",
    "    # for x, y in batch_iter(xt, y=yt, bptt=bptt, evaluation=eval):\n",
    "    for bix in barray.batch_ix_iter(batch_size=batch_size):\n",
    "        x, y = barray[bix]\n",
    "#         for batch in x.data:\n",
    "#             for row in batch:\n",
    "#                 all_elemsb = all_elemsb | set([tuple(row.numpy().ravel())])\n",
    "        optimizer.zero_grad()\n",
    "        # output, hidden = model(x, hidden)\n",
    "        output = model(x, hidden)\n",
    "        # hidden = repackage_hidden(hidden)\n",
    "        \n",
    "        res.append(output.data.squeeze())\n",
    "        if eval:\n",
    "            continue\n",
    "\n",
    "        loss = criterion(output, y.view(-1, 1))\n",
    "        loss.backward()\n",
    "\n",
    "        T.nn.utils.clip_grad_norm(model.parameters(), 3)\n",
    "\n",
    "    #     norms = []\n",
    "        maxnorm = max(T.norm(p.grad.data) for p in m.parameters())\n",
    "        if maxnorm > train_epoch.mnorm:\n",
    "            train_epoch.mnorm = maxnorm\n",
    "            print('max(grad) = {:.3f}'.format(maxnorm))\n",
    "\n",
    "        optimizer.step()\n",
    "        tot_loss += loss\n",
    "    res = T.stack(res).view(-1).numpy()\n",
    "    if eval:\n",
    "        return res\n",
    "    return tot_loss, res\n",
    "     \n",
    "train_epoch.mnorm = 0\n",
    "# tot_loss, hidden, res = train(model=model, hidden=None, brange=brange, batch_getter=batch_getter, optimizer=optimizer)\n",
    "# print(tofloat(tot_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.set_hidden(10)\n",
    "ba = BatchArray(x=xt, y=yt, seq_len=50, batch_size=10)\n",
    "trn_y = np.concatenate([ba[bix][1].data.numpy().ravel() for bix in ba.batch_ix_iter()])\n",
    "feather.write_dataframe(DataFrame(trn_y), '/tmp/res/y.fth')\n",
    "L = len(trn_y)\n",
    "# ba.batch_ix_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir /tmp/res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse(trn_y, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bix in ba.batch_ix_iter():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tot_loss, res = train_epoch(ba, model=model, hidden=None, optimizer=optimizer)\n",
    "# tot_loss, res = train_epoch(xt, yt, model=model, hidden=None, bptt=50, optimizer=optimizer)\n",
    "# tot_loss, res = train(model=model, hidden=None, brange=brange, batch_getter=batch_getter, optimizer=optimizer)\n",
    "tot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv /tmp/res/ /tmp/res_10/\n",
    "%mkdir /tmp/res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm /tmp/res/x*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Time: {:.2f}'.format(tt))\n",
    "print('Acc: {:.2f}'.format(mse(res, trn_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = time.perf_counter()\n",
    "# losses = []\n",
    "# losses.append((mse(_yeval, res), tofloat(tot_loss)))\n",
    "\n",
    "# for i in range(1):\n",
    "for i in range(2000):\n",
    "# for i in range(1000, 2000):\n",
    "# for i in range(2000, 4000):\n",
    "# for i in range(4000, 10000):\n",
    "    tot_loss, res = train_epoch(ba, model=model, hidden=None, optimizer=optimizer)\n",
    "\n",
    "    print('.', end='')\n",
    "    if i % 99 == 0:\n",
    "        print()\n",
    "        print('{:,.3f}; {:,.3f}'.format(mse(trn_y, res), tofloat(tot_loss)))\n",
    "        feather.write_dataframe(DataFrame(res), '/tmp/res/x{:05}.fth'.format(i))\n",
    "\n",
    "tt = time.perf_counter() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = train_epoch(ba, model=model, optimizer=optimizer, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Time: {:.2f}'.format(tt))\n",
    "print('Acc: {:.2f}'.format(mse(res, trn_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = 'model/gru3.mod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# T.load(model.state_dict(), 'model/gru1.mod')\n",
    "model.load_state_dict(T.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leftovers = np.prod(yt.size()) - L\n",
    "batches_left = leftovers / seq_len\n",
    "print('leftovers:', leftovers)\n",
    "print('batches_left:', batches_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xdf[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtst = collapse_dims(xt, [(0, 1), (2,)])[-leftovers:]\n",
    "# xtst = \n",
    "ytst = collapse_dims(yt, [(0, 1)])[-leftovers:]\n",
    "# xtst, ytst = map(Variable, [xtst, ytst])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_range_df(d1, d2):\n",
    "    if isinstance(d1, int):\n",
    "        rg1 = pd.date_range('2017-01-01', '2017-12-31', freq='d')\n",
    "        d1, d2 = rg1[d1], rg1[d2]\n",
    "    drg = pd.date_range(d1, d2, freq='MS')\n",
    "\n",
    "    return drg\n",
    "date_range_df(1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/len xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = train_epoch(ba, model=model, optimizer=optimizer, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf_ = xdf.ix[rx_.index].assign(D=lambda x: x.Dt.dt.day)\n",
    "pdf_['Pred'] = 0\n",
    "pdf_.loc[pdf_.index[:L], 'Pred'] = res\n",
    "\n",
    "pdf = pdf_.query('Yr >= 2013 & M < 6')\n",
    "this_year = pdf.query('Yr == 2017')\n",
    "# 'Doy', 'Temp_avg', 'M', 'Dt'\n",
    "\n",
    "def plot(x, y, m, date, dashed=None, **_):\n",
    "    global d\n",
    "    ycol = y.name\n",
    "    d = date\n",
    "\n",
    "    bm = m <= 4\n",
    "    if dashed is None:\n",
    "        plt.plot(x, y)\n",
    "    else:\n",
    "        plt.plot(x, y, '--')\n",
    "    \n",
    "    drg = pd.date_range(date.iloc[0], date.iloc[-1], freq='MS')\n",
    "    yo, yi = plt.ylim()\n",
    "    xd = drg.dayofyear\n",
    "    labs = drg.strftime(\"%b\")\n",
    "    plt.vlines(xd, 0, yi / 10)\n",
    "    \n",
    "    for xl, lab in zip(xd, labs):\n",
    "        plt.text(xl, yi / 7, lab)\n",
    "        \n",
    "    if dashed is None:\n",
    "        plt.plot(this_year.Doy, this_year[ycol], '--')\n",
    "#         plot(this_year.Doy, this_year.Temp_avg, this_year.M, this_year.Dt, dashed=True, **_)\n",
    "    else:\n",
    "        return\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/len rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/len pdf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check DF alignment by making sure they're 100% correlated\n",
    "# after StandardScaler\n",
    "fcols = pdf_.columns[(pdf_.dtypes == float) | (pdf_.dtypes == int)]\n",
    "_, cols_ = xt.size()\n",
    "for col in range(cols_):\n",
    "    feat = xt.numpy()[:, col]\n",
    "    cor = pdf_[fcols].reset_index(drop=1).corrwith(Series(feat)).round(4)\n",
    "    close_col = cor.idxmax()\n",
    "    assert cor[close_col] == 1\n",
    "    print('{}: {:.2%}'.format(close_col, cor[close_col]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=pdf, row='Yr', aspect=6)\n",
    "# g.map(plot, 'Doy', 'Cnt', 'M', 'Dt')\n",
    "g.map(plot, 'Doy', 'Pred', 'M', 'Dt', dashed=True)\n",
    "g.map(plot, 'Doy', 'Logcnt', 'M', 'Dt', dashed=True)\n",
    "plt.legend(['Predicted', 'Actual'])\n",
    "# plt.savefig('plots/annual_temps.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Held out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = len(xt) - L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldays = rx_.iloc[-2*l:].assign(Yr=lambda x: (x.Doy.shift() > x.Doy).fillna(False).astype(int).cumsum().add(2013))\n",
    "ldays['Dt'] = np.concatenate([pd.date_range('{}-01-01'.format(yr), '{}-12-31'.format(yr), freq='D')[gdf.Doy - 1].date\n",
    "                for yr, gdf in ldays.groupby(['Yr'], sort=False)])\n",
    "\n",
    "ld1, ld2 = np.array_split(ldays, 2)\n",
    "# yr2015 = pd.date_range('2015-01-01', '2016-01-01', freq='D')[ld1 - 1]\n",
    "# yr2016 = pd.date_range('2016-01-01', '2017-01-01')[ld2 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unvar = lambda x: x.data.numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "ba2 = BatchArray(x=xt[-2 * l:], y=yt[-2 * l:], seq_len=l, batch_size=1)\n",
    "xs_, ysv_ = ba2[[0]]\n",
    "xs, ysv = ba2[[1]]\n",
    "\n",
    "ys_ = Series(unvar(ysv_), index=ld1.Dt)\n",
    "ys = Series(unvar(ysv), index=ld2.Dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run prediction\n",
    "model.set_hidden(1)\n",
    "yspred_ = model(xs_, update_hidden=True)\n",
    "yspred = model(xs, update_hidden=True)\n",
    "\n",
    "yspred_ = Series(unvar(yspred_), index=ld1.Dt)\n",
    "yspred = Series(unvar(yspred), index=ld2.Dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, [ax1, ax2] = plt.subplots(2, 1, figsize=(20, 20))\n",
    "\n",
    "yspred_.plot(style='.-', ax=ax1, label='Pred')\n",
    "ys_.plot(style='.-', ax=ax1, label='Y')\n",
    "\n",
    "yspred.plot(style='.-', ax=ax2, label='Pred')\n",
    "ys.plot(style='.-', ax=ax2, label='Y')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = -90\n",
    "plt.plot(yr2015.date[:n], _y[:n], '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y = unvar(yspred_)\n",
    "plt.plot(yr2015, _y, '.-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, [ax1, ax2] = plt.subplots(2, 1, figsize=(20, 20))\n",
    "ax1.plot(unvar(yspred_), '.-')\n",
    "ax1.plot(unvar(ys_), '.-')\n",
    "# ax1.set_xticklabels(ld1)\n",
    "ax1.set_xticklabels(yr2015)\n",
    "ax1.legend(['Pred', 'Cnt'])\n",
    "\n",
    "ax2.plot(unvar(yspred), '.-')\n",
    "ax2.plot(unvar(ys), '.-')\n",
    "ax2.legend(['Pred', 'Cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(unvar(yspred))\n",
    "plt.plot(unvar(ys))\n",
    "plt.legend(['Pred', 'Cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_hidden(10)\n",
    "ba = BatchArray(x=xt, y=yt, seq_len=50, batch_size=10)\n",
    "trn_y = np.concatenate([ba[bix][1].data.numpy().ravel() for bix in ba.batch_ix_iter()])\n",
    "feather.write_dataframe(DataFrame(trn_y), '/tmp/res/y.fth')\n",
    "L = len(trn_y)\n",
    "# ba.batch_ix_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resho = train_epoch(ba2, model=model, optimizer=optimizer, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_y = np.concatenate([ba[bix][1].data.numpy().ravel() for bix in ba.batch_ix_iter()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "ax = plt.gca()\n",
    "pdf.query('Yr >= 2012').set_index(['Doy', 'Yr']).Temp_avg.unstack().plot(ax=ax)  #.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "xdf.query('Yr > 2014').set_index('Dt').Cnt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "87 * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_x, _y = batch_getter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = float(np.array(1))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tot_loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(tot_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "_x, _y = batch_getter(0)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output, h1 = model(_x, h0)\n",
    "h1 = repackage_hidden(h1)\n",
    "\n",
    "loss = criterion(output, _y.view(-1, 1))\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "output2, h2 = model(_x, h2)\n",
    "h2 = repackage_hidden(h2)\n",
    "\n",
    "loss = criterion(output2, _y.view(-1, 1))\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_y.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.decoder.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_y.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn = nn.GRU(P, nhidden, num_layers, batch_first=True)\n",
    "rnn.zero_grad()\n",
    "decoder = nn.Linear(nhidden, 1)\n",
    "\n",
    "input = Variable(T.randn(bcz, seq_len, P))\n",
    "h0 = Variable(T.randn(num_layers, bcz, nhidden))\n",
    "\n",
    "# output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_x, _y = batch_getter(0)\n",
    "output, h1 = rnn(_x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out2 = decoder(output.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h1.data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # rnn = nn.LSTM(P, nhidden, num_layers)\n",
    "    input = Variable(T.randn(5, bcz, P))\n",
    "    h0 = Variable(T.randn(bcz, num_layers, nhidden))\n",
    "    # c0 = Variable(T.randn(num_layers, bcz, nhidden))\n",
    "    output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(P, nhidden, num_layers)\n",
    "input = Variable(torch.randn(5, bcz, P))\n",
    "h0 = Variable(torch.randn(num_layers, bcz, nhidden))\n",
    "c0 = Variable(torch.randn(num_layers, bcz, nhidden))\n",
    "output, hn = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.random.randint(-5, 5, size=(N, P)).astype(np.float32)\n",
    "xsub = to_sub_seqs(x, seq_len=3)\n",
    "xt = torch.from_numpy(xsub)\n",
    "\n",
    "rnn = nn.GRU(P, nhidden, 1, batch_first=True)\n",
    "rnn.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r(v, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x0 = T.unsqueeze(xx[0], 0)\n",
    "x0 = xx[0:4]\n",
    "v = Variable(x0, requires_grad=True)\n",
    "rnn(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin = nn.Linear(3, 20)\n",
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin(Variable(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T.randn(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.r_[0, sm[:-1]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_t[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_d.sum(dim=1)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Rnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "Rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable, Reporter\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN\n",
    "Dummy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2var = lambda x: Variable(x.values.astype('f'))\n",
    "tovar = lambda x: Variable(x.astype('f'))\n",
    "Variable.flt = lambda x: float(x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_train_(model, x, y, batch_size=50, clip=None):\n",
    "    rnn = model.predictor\n",
    "    loss = 0\n",
    "    N = len(y)\n",
    "    ix_rng = range(0, N, batch_size)\n",
    "    final = len(ix_rng) - 1\n",
    "    for i, ix in enumerate(ix_rng):\n",
    "        loss += model(x[ix:ix+batch_size], y[ix:ix+batch_size])\n",
    "        # print('{}-{}'.format(ix, ix+batch_size), end=';')\n",
    "        if ((i + 1) % 10 == 0) or (i == final):\n",
    "            # print('.!.', end='')\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            loss.unchain_backward()\n",
    "            if clip:\n",
    "                optimizer.clip_grads(clip)\n",
    "            optimizer.update()\n",
    "            rnn.reset_state()  # ?\n",
    "            loss = 0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_len = 3\n",
    "batch_len = 2\n",
    "\n",
    "for b in range(batch_len):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_x, *_ = x\n",
    "_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1, r2 = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Regressor(Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super().__init__(predictor=predictor)\n",
    "        \n",
    "    def __call__(self, x, t):\n",
    "        y = self.predictor(x)\n",
    "        loss = F.mean_squared_error(y, t)\n",
    "        reporter.report({'loss': loss}, self)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "class RNN(Chain):\n",
    "    def __init__(self, P):\n",
    "        super().__init__(\n",
    "            in_=L.Linear(P, 100),  # word embedding\n",
    "            mid=L.LSTM(100, 128),  # the first LSTM layer\n",
    "            out=L.Linear(128, 1),  # the feed-forward output layer\n",
    "        )\n",
    "\n",
    "    def reset_state(self):\n",
    "        # print('RS!')\n",
    "        self.mid.reset_state()\n",
    "\n",
    "    def __call__(self, X):\n",
    "        # Given the current data, predict the next data point.\n",
    "        return z.pipe(X, self.in_, self.mid, self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_model(P):\n",
    "    rnn = RNN(P)             # x    -> pred\n",
    "    model = Regressor(rnn)  # x, t -> score\n",
    "    model.cleargrads()\n",
    "\n",
    "    optimizer = optimizers.Adam()\n",
    "    # optimizer = optimizers.SGD()\n",
    "    optimizer.use_cleargrads()\n",
    "    optimizer.setup(model)\n",
    "\n",
    "    reporter = Reporter()\n",
    "    reporter.add_observer('model', model)\n",
    "    return model, rnn, reporter, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: principled approach to iters, batch size, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(np.prod([8,8,3]) + 1) * np.prod([14,14,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_height, filter_height = 32, 8\n",
    "P = 1\n",
    "S = 2\n",
    "(input_height - filter_height + 2 * P)/S + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, rnn, reporter, optimizer = mk_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_train(model, x, y, batch_size=5, train_len=100, clip=None):\n",
    "    mk_batch = partial(batchify, batch_size=batch_size, train_len=train_len)\n",
    "    rnn = model.predictor\n",
    "    loss = 0\n",
    "    N = len(y)\n",
    "    \n",
    "    # TODO: simplify\n",
    "    ix_rng = range(0, N, batch_size)\n",
    "    final = len(ix_rng) - 1\n",
    "    \n",
    "#     TODO: why no len???\n",
    "#     mb = mk_batch(x)\n",
    "    print(len(mk_batch(y)))\n",
    "    print(len(mk_batch(x)))\n",
    "    \n",
    "    for i, batchx, batchy in zip(\n",
    "        count(), mk_batch(x), mk_batch(y)):\n",
    "        print(i)\n",
    "        loss += model(tovar(batchx), tovar(batchy))\n",
    "        # print('{}-{}'.format(ix, ix+batch_size), end=';')\n",
    "        if ((i + 1) % 10 == 0) or (i == final):\n",
    "            print('.!.', end='')\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            loss.unchain_backward()\n",
    "            if clip:\n",
    "                optimizer.clip_grads(clip)\n",
    "            optimizer.update()\n",
    "            rnn.reset_state()  # ?\n",
    "            loss = 0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predictor.in_.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InvalidType: \n",
    "Invalid operation is performed in: LinearFunction (Forward)\n",
    "\n",
    "Expect: prod(in_types[0].shape[1:]) == in_types[1].shape[1]\n",
    "Actual: 300 != 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    batch_train(model, xx.data, yy.data, batch_size=5, train_len=100)\n",
    "rnn.reset_state()\n",
    "# model(xx.data, yy.data).flt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mk_batch = partial(batchify, batch_size=2, train_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs = mk_batch(xx.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchify(xx.data, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/len xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/len yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_(x, y, batch_size=5):\n",
    "    loss = 0\n",
    "    for i in range(0, len(y) - batch_size, batch_size):\n",
    "        loss += model(x[i:i+batch_size], y[i:i+batch_size])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(x, y):\n",
    "    loss = 0\n",
    "    for i in range(0, len(y)):\n",
    "        loss += model(x[i:i+1], y[i:i+1])\n",
    "        print(loss.flt())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # All at once ok w/ N=1000\n",
    "    for i in range(20):\n",
    "        loss = model(xx, yy)\n",
    "\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "    #     loss.unchain_backward()\n",
    "     #   optimizer.clip_grads(5)\n",
    "        optimizer.update()\n",
    "\n",
    "    \n",
    "    \n",
    "    # All at once ok w/ N=1000\n",
    "    for i in range(20):\n",
    "        loss = model(xx, yy)\n",
    "\n",
    "        if i:\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            optimizer.clip_grads(50)\n",
    "            optimizer.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = RNN()             # x    -> pred\n",
    "model = Regressor(rnn)  # x, t -> score\n",
    "model.cleargrads()\n",
    "\n",
    "optimizer = optimizers.Adam()\n",
    "# optimizer = optimizers.SGD()\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(model)\n",
    "\n",
    "reporter = Reporter()\n",
    "reporter.add_observer('model', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All at once ok w/ N=1000\n",
    "_rng = np.arange(N)\n",
    "for i in range(20):\n",
    "    loss = model(xx, yy)\n",
    "    \n",
    "    # if (i + 1) % 50 == 0:\n",
    "    if i:\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "    #     loss.unchain_backward()\n",
    "        optimizer.clip_grads(50)\n",
    "        optimizer.update()\n",
    "\n",
    "loss.flt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_rng = np.arange(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 20\n",
    "r = range(n)\n",
    "b = 3\n",
    "jump = n // b\n",
    "list(range(0, jump))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in list(range(0, jump)):\n",
    "    print(i)\n",
    "    ix = [r[(jump * j + i) % n] for j in range(b)]\n",
    "    print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ix_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Batch size five\n",
    "\n",
    "loss = 0\n",
    "BATCH_SIZE = 50\n",
    "ix_rng = range(0, N, BATCH_SIZE)\n",
    "# for i in range(100):\n",
    "for i, ix in enumerate(ix_rng):\n",
    "    # loss = compute_loss(xn, yn)\n",
    "    loss += model(xx[ix:ix+BATCH_SIZE], yy[ix:ix+BATCH_SIZE])\n",
    "    print('{}-{}'.format(ix, ix+BATCH_SIZE), end=';')\n",
    "    if ((i + 1) % 10 == 0) or (i == len(ix_rng) - 1):\n",
    "        print('.!.', end='')\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        loss.unchain_backward()\n",
    "#         optimizer.clip_grads(500)\n",
    "        optimizer.update()\n",
    "        rnn.reset_state()  # ?\n",
    "        loss = 0\n",
    "\n",
    "# loss.flt()\n",
    "\n",
    "rnn.reset_state()\n",
    "model(xx, yy).flt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.shape[0] -> batch size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn.reset_state()\n",
    "\n",
    "plt.plot(yy.data.ravel(), rnn(xx).data.ravel(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataFrame(OrderedDict([('Act', yy.data.ravel()), ('Pred', rnn(xx).data.ravel().round(1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn.mid.h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yy.data.ravel()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_loss(xn, yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "loss = 0\n",
    "rnn.reset_state()\n",
    "model.cleargrads()\n",
    "for i in range(0, len(yn), BATCH_SIZE):\n",
    "    # print(i, i + BATCH_SIZE)\n",
    "    loss += model(xn[i:i+BATCH_SIZE], yn[i:i+BATCH_SIZE])\n",
    "    print(float(loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x, y in zip(xn, yn):\n",
    "    model(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xn.data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(xs, ys):\n",
    "    loss = 0\n",
    "    for x, y in zip(xs, ys):\n",
    "        loss += model(x, y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_loss(xn, yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = model(xn, yn)\n",
    "show_grads()\n",
    "loss.backward()\n",
    "show_grads()\n",
    "optimizer.update()\n",
    "show_grads()\n",
    "\n",
    "loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valloss = model(xs, ys)\n",
    "model.cleargrads()\n",
    "valloss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = rnn(xn)\n",
    "pred.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reporter.observation['model/loss'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((y13 - pred.data) ** 2).sum() / len(y13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xn.volatile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_grads = lambda: print(rnn.in_.W.grad[:2, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rnn.in_.W.grad[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn.in_.W.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reporter.observation['model/loss'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lossfun(arg1, arg2):\n",
    "    # calculate loss\n",
    "    loss = F.sum(model(arg1 - arg2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F.MeanSquaredError(y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(x_list):\n",
    "    loss = 0\n",
    "    for cur_word, next_word in zip(x_list, x_list[1:]):\n",
    "        loss += model(cur_word, next_word)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Classifier(Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super(Classifier, self).__init__(predictor=predictor)\n",
    "        \n",
    "    def __call__(self, x, t):\n",
    "        y = self.predictor(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        accuracy = F.accuracy(y, t)\n",
    "        report({'loss': loss, 'accuracy': accuracy}, self)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = datasets.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super().__init__(  # MLP, self\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            l1=L.Linear(None, n_units),  # n_in -> n_units\n",
    "            l2=L.Linear(None, n_units),  # n_units -> n_units\n",
    "            l3=L.Linear(None, n_out),    # n_units -> n_out\n",
    "        )\n",
    "        \n",
    "    def call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        y = self.l3(h2)\n",
    "        return y\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return z.compose(self.l3, F.relu, self.l2, F.relu, self.l1)(x)\n",
    "        return z.pipe(x, self.l1, F.relu, self.l2, F.relu, self.l3)\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        y = self.l3(h2)\n",
    "        return y\n",
    "\n",
    "\n",
    "model = L.Classifier(MLP(100, 10))\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter = iterators.SerialIterator(train, batch_size=100, shuffle=True)\n",
    "\n",
    "test_iter = iterators.SerialIterator(test, batch_size=100, repeat=False, shuffle=False)\n",
    "\n",
    "updater = training.StandardUpdater(train_iter, optimizer)\n",
    "trainer = training.Trainer(updater, (20, 'epoch'), out='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.extend(extensions.Evaluator(test_iter, model))\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy']))\n",
    "# trainer.extend(extensions.ProgressBar())\n",
    "trainer.run()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = np.array([5], dtype=np.float32)\n",
    "x = Variable(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> l1 = L.Linear(4, 3)\n",
    ">>> l2 = L.Linear(3, 2)\n",
    ">>> def my_forward(x):\n",
    "...     h = l1(x)\n",
    "...     return l2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr.seed(0)\n",
    "x = Variable(nr.random((2, 4)).astype(np.float32))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = my_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.finfo(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm = Sequential([\n",
    "    LSTM(\n",
    "        input_dim=P,\n",
    "        output_dim=4,\n",
    "        return_sequences=True\n",
    "    ),\n",
    "    Dense(output_dim=2),\n",
    "#     Activation('linear'),\n",
    "])\n",
    "\n",
    "\n",
    "lstm.compile(loss=\"mse\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lstm.fit(x13.values[None, :, :], y13, batch_size=32, nb_epoch=epochs, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1, ld, la = lstm.layers\n",
    "l1.input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "_x, _y = create_dataset(xd[['Temp_avg']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xd[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame({'X': _x.ravel(), 'Y': _y[:]}).assign(T=xd.Temp_avg.tolist()[:-2])\n",
    "# _.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x13[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "xd.query('Yr == 2014').Logcnt.plot()\n",
    "res0.Logcnt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf.Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pf.GAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = pf.GASX(formula='Logcnt~1+ Temp_avg + Dew_avg + Press_avg', data=xd, ar=1, sc=1, family=pf.Skewt())\n",
    "x = model2.fit()\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.plot_fit(figsize=((15,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPNARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pf.GPNARX(xd[['Logcnt']], ar=4, kernel=pf.SquaredExponential())\n",
    "x = model.fit()\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.plot_fit(figsize=((15,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
