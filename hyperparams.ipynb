{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imports import *\n",
    "\n",
    "# %mkdir cache\n",
    "import joblib; mem = joblib.Memory(cachedir='cache')\n",
    "\n",
    "import toolz.curried as z\n",
    "\n",
    "import torch as T\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from functools import wraps\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import util.pollen_utils; reload(util.pollen_utils); from util.pollen_utils import (\n",
    "    pollen_url, pollen_date2df as pollen_date2df_, pollen_data as pollen_data_,\n",
    "    parse_pollen_page\n",
    ")\n",
    "\n",
    "import util.utils; reload(util.utils); from util.utils import (\n",
    "    check_one2one, yrmths, flatten_multindex, ends_with,\n",
    "    collapse_dims, test_collapse_dims_,\n",
    "    BatchArray,\n",
    "    ravel, repackage_hidden, mse\n",
    ")\n",
    "date = lambda xs: dt.datetime(*xs)\n",
    "\n",
    "\n",
    "pollen_date2df = mem.cache(pollen_date2df_)\n",
    "pollen_data = mem.cache(pollen_data_)\n",
    "\n",
    "test_collapse_dims_(T)\n",
    ";;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rx = feather.read_dataframe('cache/x.fth').values\n",
    "rx_ = feather.read_dataframe('cache/x_.fth')\n",
    "ry = feather.read_dataframe('cache/y.fth').iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rnn(nn.Module):\n",
    "    def __init__(self, P=3, nhidden=21, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "        self.P, self.nhidden, self.num_layers, self.dropout = (\n",
    "            P, nhidden, num_layers, dropout\n",
    "        )\n",
    "        self.rnn = nn.GRU(P, nhidden, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.Dropout = nn.Dropout(p=dropout)\n",
    "        self.decoder = nn.Linear(nhidden, 1)\n",
    "        self.init_weights()\n",
    "        self.zero_grad()\n",
    "\n",
    "    def __dir__(self):\n",
    "        return super().__dir__() + list(self._modules)\n",
    "    \n",
    "    def forward(self, input, hidden=None, outputh=False):\n",
    "        if hidden is None:\n",
    "            hidden = self.hidden\n",
    "        out1, hout = self.rnn(input, hidden)\n",
    "        out1d = self.Dropout(out1)\n",
    "        out2 = self.decoder(ravel(out1d))\n",
    "        self.hidden = repackage_hidden(hout)\n",
    "        if outputh:\n",
    "            return out2, hout\n",
    "        return out2\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        \"For lstm I'll need to return 2\"\n",
    "        weight = next(self.rnn.parameters()).data\n",
    "        mkvar = lambda: Variable(weight.new(self.num_layers, bsz, self.nhidden).zero_())\n",
    "        return mkvar()\n",
    "    \n",
    "    def set_hidden(self, bsz):\n",
    "        h = self.init_hidden(bsz)\n",
    "        self.hidden = h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(barray, model=None, hidden=None, optimizer=None, eval=False, batch_size=None):\n",
    "    batch_size = batch_size or barray.batch_size\n",
    "    assert batch_size or hidden\n",
    "    if hidden is None:\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "    res = []\n",
    "    global x, y, output, loss\n",
    "    ss, _n = 0, 0\n",
    "\n",
    "    for bix in barray.batch_ix_iter(batch_size=batch_size):\n",
    "        x, y = barray[bix]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, hidden)\n",
    "        \n",
    "        res.append(output.data.squeeze())\n",
    "        if eval:\n",
    "            continue\n",
    "\n",
    "        loss = criterion(output, y.view(-1, 1))\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        T.nn.utils.clip_grad_norm(model.parameters(), 3)\n",
    "\n",
    "        maxnorm = max(T.norm(p.grad.data) for p in model.parameters())\n",
    "        if maxnorm > train_epoch.mnorm:\n",
    "            train_epoch.mnorm = maxnorm\n",
    "            print('max(grad) = {:.3f}'.format(maxnorm))\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        ss += tofloat(loss) * len(output)  # keep track of ss\n",
    "        _n += len(output)\n",
    "\n",
    "    res = T.stack(res).view(-1).numpy()\n",
    "    if eval:\n",
    "        return res\n",
    "    tot_loss = ss / _n\n",
    "    return tot_loss, res\n",
    "     \n",
    "train_epoch.mnorm = 0\n",
    "# tot_loss, hidden, res = train(model=model, hidden=None, brange=brange, batch_getter=batch_getter, optimizer=optimizer)\n",
    "# print(tofloat(tot_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALFN = '/tmp/res/val.txt'\n",
    "TRNFN = '/tmp/res/trn.txt'\n",
    "\n",
    "def report_hook(model, res, vals=None):\n",
    "    print()\n",
    "    val_pred(model, warmup=True)\n",
    "    yspred, ys = val_pred(model, warmup=False)\n",
    "    val_acc = mse(yspred, ys)\n",
    "    vals.append(val_acc)\n",
    "    trn_acc = mse(trn_y, res)\n",
    "\n",
    "    with open(VALFN, 'a') as f:\n",
    "        f.write('{:}\\n'.format(val_acc))\n",
    "    with open(TRNFN, 'a') as f:\n",
    "        f.write('{:}\\n'.format(trn_acc))\n",
    "    print('{:,.3f}; val: {:,.4f}'.format(trn_acc, val_acc), end='; ')\n",
    "\n",
    "    \n",
    "def train_epochs(model, optimizer=None, rng=(500, ), print_every=10, report_hook=None, report_kw={}):\n",
    "    with open(VALFN, 'w') as f: pass\n",
    "    with open(TRNFN, 'w') as f: pass\n",
    "    vals = []\n",
    "    \n",
    "    for i in range(*rng):\n",
    "        _, res = train_epoch(ba, model=model, hidden=None, optimizer=optimizer)\n",
    "\n",
    "        print('.', end='')\n",
    "        if i % print_every == 0:\n",
    "            if report_hook:\n",
    "                report_hook(model, res, vals=vals)\n",
    "        \n",
    "    return res, min(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dates(df, l):\n",
    "    \"\"\"Batches will have `l` leftover elements.\n",
    "    I have stripped out the dates from the features,\n",
    "    and just left day of the year integers, so this function\n",
    "    reconstructs the actual dates from these day of year features.\n",
    "    \"\"\"\n",
    "    ldays = df.iloc[-2 * l:].assign(\n",
    "        Yr=lambda x: (x.Doy.shift() > x.Doy  # New year when\n",
    "                      ).fillna(False).astype(int).cumsum()  #.add(2000)\n",
    "    )\n",
    "    ldays['Yr'] = ldays['Yr'] + (2017 - ldays['Yr'].max())\n",
    "    ldays['Dt'] = np.concatenate([pd.date_range('{}-01-01'.format(yr), '{}-12-31'.format(yr), freq='D')[gdf.Doy - 1].date\n",
    "                                  for yr, gdf in ldays.groupby(['Yr'], sort=False)])\n",
    "\n",
    "    ld1, ld2 = np.array_split(ldays, 2)\n",
    "    return ld1, ld2, ldays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_pred(model, warmup=True):\n",
    "    if warmup:\n",
    "        model.set_hidden(1)\n",
    "\n",
    "    ix = int(not warmup)\n",
    "    Dt = baval.Dt[ix]\n",
    "    xs, ysv = baval[[ix]]\n",
    "\n",
    "    ys = Series(unvar(ysv), index=Dt)\n",
    "    yspred = model(xs)\n",
    "\n",
    "    yspred_s = Series(unvar(yspred), index=Dt)\n",
    "    return yspred_s, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xt = T.from_numpy(rx)\n",
    "yt = T.from_numpy(ry.values[:, None])\n",
    "print(xt.size())\n",
    "print(yt.size())\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len = 25\n",
    "bcz = 32\n",
    "# bcz = 64\n",
    "# bcz = 128\n",
    "# bcz = 512\n",
    "ba = BatchArray(x=xt, y=yt, seq_len=seq_len, batch_size=bcz)\n",
    "trn_y = np.concatenate([ba[bix][1].data.numpy().ravel() for bix in ba.batch_ix_iter()])\n",
    "\n",
    "L = len(trn_y)\n",
    "l = len(xt) - L\n",
    "print('L=', L, 'l=', l)\n",
    "ld1, ld2, _ = add_dates(rx_, l)\n",
    "\n",
    "baval = BatchArray(x=xt[-2 * l:], y=yt[-2 * l:], seq_len=l, batch_size=1)\n",
    "baval.Dt = [ld1.Dt, ld2.Dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tofloat = lambda x: x.data[0]\n",
    "unvar = lambda x: x.data.numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opt_func(x):\n",
    "    print('==> Starting', x)\n",
    "    nhidden, num_layers, dropout, lr, opt_method = x\n",
    "    n_iters = 50\n",
    "    model = Rnn(P=rx.shape[-1], nhidden=nhidden, num_layers=num_layers, dropout=dropout)\n",
    "    \n",
    "    opter = getattr(optim, opt_method)      # RMSprop, Adam\n",
    "    optimizer = opter(model.parameters(), lr=lr)\n",
    "    \n",
    "    vals = []\n",
    "    \n",
    "    st = time.perf_counter()\n",
    "    res, mvals = train_epochs(model=model, optimizer=optimizer, rng=(n_iters, ),\n",
    "                         print_every=5, report_hook=report_hook,\n",
    "                         report_kw={'vals': vals}\n",
    "                        )\n",
    "    tt = time.perf_counter() - st\n",
    "\n",
    "    print('\\n\\nTime: {:.2f}'.format(tt))\n",
    "    print('Acc: {:.2f}; Val: {:.3f}'.format(mse(res, trn_y), mvals))\n",
    "    return mvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = opt_func(8, 1, dropout=0, lr=0.0025, n_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gp_minimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = gp_minimize(opt_func,                  # the function to minimize\n",
    "                  [\n",
    "                      [8, 16, 32, 64, 128],     # nhidden\n",
    "                      [1, 2, 3],   # num_layers\n",
    "                      [.01, .05, .1, .15, .2, .5],              # dropout\n",
    "                      [.0005, .001, .002, .0025, .005], # lr\n",
    "                      ['RMSprop', 'Adam'],                # opt_method\n",
    "                  ],      \n",
    "#                   acq_func=\"EI\",      # the acquisition function\n",
    "                  n_calls=150,         # the number of evaluations of f \n",
    "                  n_random_starts=5,  # the number of random initialization points\n",
    "#                   noise=0.1**2,       # the noise level (optional)\n",
    "                  random_state=123)   # the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# opt_func([64, 3, .01, 0.0050, 'Adam'])\n",
    "# opt_func([64, 3, .05, 0.0010, 'Adam'])\n",
    "opt_func([128, 2, .05, 0.001, 'Adam'])  # => good\n",
    "# opt_func([32, 3, .05, 0.002, 'Adam'])  # => "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = (DataFrame(res['x_iters'], columns='Nhidden Num_layers Dropout Lr Opt_method'.split())\n",
    "      .assign(Dropout=lambda x: x.Dropout.mul(100).round(1))\n",
    "     )\n",
    "df['Y'] = res['func_vals']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfw = df.sort_values('Y', ascending=True).reset_index(drop=1)\n",
    "feather.write_dataframe(dfw, 'cache/skopt_res.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfw.to_csv('/tmp/sko.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfw.groupby('Dropout').Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfw.groupby('Lr').Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfw.groupby('Nhidden').Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfw.groupby('Num_layers').Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfw.groupby(['Nhidden', 'Num_layers', ]).Y.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfw.groupby('Opt_method').Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_values('Y', ascending=True)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res['func_vals']\n",
    "res['x_iters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nhidden = 32\n",
    "num_layers = 2\n",
    "model = Rnn(P=rx.shape[-1], nhidden=nhidden, num_layers=num_layers, dropout=.5)\n",
    "model.set_hidden(bcz)\n",
    "# m = model = Rnn()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0025)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr = 0.002)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "30\n",
    "30\n",
    "30\n",
    "16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
